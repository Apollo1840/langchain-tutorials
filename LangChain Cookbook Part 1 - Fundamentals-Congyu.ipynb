{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d09592",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe475c",
   "metadata": {},
   "source": [
    "- install necessary packages\n",
    "- setup the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341d995f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (0.2.10)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (0.2.22)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (0.1.93)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (1.21.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.22->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/congyu/anaconda3/envs/congyutf/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements_congyu.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e47a6",
   "metadata": {},
   "source": [
    "- Where to get openai_key: https://platform.openai.com/api-keys\n",
    "- Where to get gemini_key: https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79741fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY', 'YourAPIKey')\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\", \"YourAPIKey\")\n",
    "\n",
    "# print(openai_api_key)\n",
    "# print(google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c17639",
   "metadata": {},
   "source": [
    "or do these in terminal: \n",
    "\n",
    "```export OPENAI_API_KEY=\"value\"```\n",
    "\n",
    "```export GOOGLE_API_KEY=\"value\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d71ac6",
   "metadata": {},
   "source": [
    "test API works or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5b1795b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"chatcmpl-ARddD9oiXrSwOufSzhWORCcnNQMU9\",\r\n",
      "  \"object\": \"chat.completion\",\r\n",
      "  \"created\": 1731150563,\r\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\r\n",
      "  \"choices\": [\r\n",
      "    {\r\n",
      "      \"index\": 0,\r\n",
      "      \"message\": {\r\n",
      "        \"role\": \"assistant\",\r\n",
      "        \"content\": \"Artificial Intelligence, or AI, is a branch of computer science that aims to create machines or systems that can perform tasks that typically require human intelligence. AI works by using algorithms and data to mimic cognitive functions such as learning, problem-solving, perception, and decision-making.\\n\\nThere are different approaches to AI, including symbolic AI, which uses rules and logic to manipulate symbols, and machine learning, which relies on data and algorithms to improve performance over time. Machine learning is a subset of AI, and it\",\r\n",
      "        \"refusal\": null\r\n",
      "      },\r\n",
      "      \"logprobs\": null,\r\n",
      "      \"finish_reason\": \"length\"\r\n",
      "    }\r\n",
      "  ],\r\n",
      "  \"usage\": {\r\n",
      "    \"prompt_tokens\": 12,\r\n",
      "    \"completion_tokens\": 100,\r\n",
      "    \"total_tokens\": 112,\r\n",
      "    \"prompt_tokens_details\": {\r\n",
      "      \"cached_tokens\": 0,\r\n",
      "      \"audio_tokens\": 0\r\n",
      "    },\r\n",
      "    \"completion_tokens_details\": {\r\n",
      "      \"reasoning_tokens\": 0,\r\n",
      "      \"audio_tokens\": 0,\r\n",
      "      \"accepted_prediction_tokens\": 0,\r\n",
      "      \"rejected_prediction_tokens\": 0\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"system_fingerprint\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!(curl https://api.openai.com/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
    "  -d '{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Explain how AI works\"}],\"max_tokens\": 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f404b47",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"candidates\": [\r\n",
      "    {\r\n",
      "      \"content\": {\r\n",
      "        \"parts\": [\r\n",
      "          {\r\n",
      "            \"text\": \"## How AI Works: A Simplified Explanation\\n\\nArtificial Intelligence (AI) is a broad field, but its core goal is to create machines that can **mimic human intelligence** in various tasks. While \\\"thinking\\\" like humans is a distant goal, AI has achieved remarkable progress in specific areas. Here's a simplified breakdown:\\n\\n**1. Learning from Data:**\\n\\n* AI systems are trained on **massive amounts of data**, like images, text, or sensor readings.\\n* This data is used to **identify patterns and relationships**, enabling the AI to learn and make predictions.\\n\\n**2. Algorithms and Models:**\\n\\n* AI employs various **algorithms**, which are sets of instructions that guide the learning process.\\n* These algorithms create **mathematical models** that represent the underlying patterns in the data.\\n\\n**3. Different Approaches:**\\n\\n* **Machine Learning (ML)** focuses on algorithms that can learn from data without explicit programming.\\n* **Deep Learning (DL)** is a subfield of ML that uses artificial neural networks, inspired by the human brain, to process complex data.\\n\\n**4. Key Tasks:**\\n\\n* **Classification:** Categorizing data into predefined classes, e.g., identifying objects in images.\\n* **Regression:** Predicting a numerical value, e.g., forecasting stock prices.\\n* **Clustering:** Grouping similar data points together, e.g., segmenting customers based on behavior.\\n* **Natural Language Processing (NLP):** Understanding and generating human language, e.g., chatbots or language translation.\\n\\n**5. Examples:**\\n\\n* **Recommendation Systems:** Suggesting products or content based on your preferences.\\n* **Image Recognition:** Identifying objects and scenes in images, used in self-driving cars.\\n* **Spam Filters:** Detecting and filtering unwanted emails.\\n* **Virtual Assistants:** Understanding and responding to voice commands, like Siri or Alexa.\\n\\n**It's important to note that AI is still under development and faces challenges:**\\n\\n* **Data Bias:** AI can perpetuate biases present in the training data.\\n* **Explainability:** Understanding how an AI reaches its conclusions can be difficult.\\n* **Ethical Concerns:** AI raises questions about privacy, job displacement, and potential misuse.\\n\\n**Overall, AI is a powerful tool with the potential to revolutionize many aspects of our lives. Understanding its basic principles can help us navigate its impact and use it responsibly.**\\n\"\r\n",
      "          }\r\n",
      "        ],\r\n",
      "        \"role\": \"model\"\r\n",
      "      },\r\n",
      "      \"finishReason\": \"STOP\",\r\n",
      "      \"index\": 0,\r\n",
      "      \"safetyRatings\": [\r\n",
      "        {\r\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\r\n",
      "          \"probability\": \"NEGLIGIBLE\"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\r\n",
      "          \"probability\": \"NEGLIGIBLE\"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\r\n",
      "          \"probability\": \"NEGLIGIBLE\"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\r\n",
      "          \"probability\": \"NEGLIGIBLE\"\r\n",
      "        }\r\n",
      "      ]\r\n",
      "    }\r\n",
      "  ],\r\n",
      "  \"usageMetadata\": {\r\n",
      "    \"promptTokenCount\": 4,\r\n",
      "    \"candidatesTokenCount\": 494,\r\n",
      "    \"totalTokenCount\": 498\r\n",
      "  },\r\n",
      "  \"modelVersion\": \"gemini-1.5-flash-001\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!(curl -X POST \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=$GEMINI_API_KEY\"\\\n",
    "       -H 'Content-Type: application/json' \\\n",
    "       -d '{\"contents\":[{\"parts\":[{\"text\":\"Explain how AI works\"}]}]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359697d5",
   "metadata": {},
   "source": [
    "# LangChain Cookbook 👨‍🍳👩‍🍳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb564d",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5c721d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e0dc06c",
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> I am a new bee, please anwser me how to use LangChain\n",
      "\n",
      "<class 'langchain_core.messages.system.SystemMessage'> You are a nice AI bot that helps a user figure out where to travel in one short sentence\n",
      "\n",
      "<class 'langchain_core.documents.base.Document'> This is my document. It is full of text that I've gathered from other places\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"text\"], template=\"I am a new bee, please anwser me {text}\")\n",
    "\n",
    "text = prompt.format(text=\"how to use LangChain\")\n",
    "print(type(text), text)\n",
    "print()\n",
    "\n",
    "\n",
    "chat_msg = [\n",
    " SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
    " HumanMessage(content=\"I like the beaches where should I go?\"),\n",
    " AIMessage(content=\"You should go to Nice, France\"),\n",
    " HumanMessage(content=\"What else should I do when I'm there?\")\n",
    "]\n",
    "print(type(chat_msg[0]), chat_msg[0].content)\n",
    "print()\n",
    "\n",
    "document = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"The LangChain Papers\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })\n",
    "print(type(document), document.page_content)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932d7c6",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5182a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8e68974",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo', temperature=1, openai_api_key=openai_api_key)\n",
    "# chat = ChatGoogleGenerativeAI(model='gemini-1.5-pro', temperature=0, google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cebb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = chat(chat_msg)\n",
    "print(ai_message)\n",
    "print()\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e50c4",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c46cf1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55da4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests, and only respond the short dish name\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "# Holds my 'location' chain\n",
    "location_chain = LLMChain(llm=chat, prompt=prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f12c167f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peking Duck'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_chain.run(\"China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cf33cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home. please respond in a very structured way.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=chat, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af8634c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Preheat the oven to 350°F.\n",
      "2. Rinse and pat dry a whole duck. \n",
      "3. Rub the duck inside and out with a mixture of soy sauce, honey, hoisin sauce, and five-spice powder.\n",
      "4. Place the duck on a roasting rack in a roasting pan.\n",
      "5. Roast the duck in the oven for about 2 hours, turning and basting it every 30 minutes.\n",
      "6. Increase the oven temperature to 425°F and roast for an additional 30 minutes to crisp up the skin.\n",
      "7. Let the duck rest for 10 minutes before carving and serving with pancakes, scallions, cucumber, and hoisin sauce. Enjoy your homemade Peking Duck!\n"
     ]
    }
   ],
   "source": [
    "print(meal_chain.run(\"Peking Duck\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a24132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mCacio e Pepe\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIngredients:\n",
      "- 8 oz spaghetti\n",
      "- 1/2 cup grated Pecorino Romano cheese\n",
      "- 1/2 cup grated Parmesan cheese\n",
      "- 2 tsp freshly ground black pepper\n",
      "- Salt to taste\n",
      "\n",
      "Instructions:\n",
      "1. Cook spaghetti in a large pot of salted boiling water until al dente. Reserve 1 cup of pasta water before draining.\n",
      "2. In a separate pan, toast black pepper over low heat until fragrant.\n",
      "3. Add 1/2 cup of pasta water to the pan and bring to a simmer.\n",
      "4. Add cooked spaghetti to the pan and toss to coat in the pepper water.\n",
      "5. Gradually add both cheeses, stirring constantly until melted and creamy. If needed, add more pasta water to achieve desired consistency.\n",
      "6. Season with salt to taste.\n",
      "7. Serve hot and enjoy your homemade Cacio e Pepe!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Ingredients:\n",
      "- 8 oz spaghetti\n",
      "- 1/2 cup grated Pecorino Romano cheese\n",
      "- 1/2 cup grated Parmesan cheese\n",
      "- 2 tsp freshly ground black pepper\n",
      "- Salt to taste\n",
      "\n",
      "Instructions:\n",
      "1. Cook spaghetti in a large pot of salted boiling water until al dente. Reserve 1 cup of pasta water before draining.\n",
      "2. In a separate pan, toast black pepper over low heat until fragrant.\n",
      "3. Add 1/2 cup of pasta water to the pan and bring to a simmer.\n",
      "4. Add cooked spaghetti to the pan and toss to coat in the pepper water.\n",
      "5. Gradually add both cheeses, stirring constantly until melted and creamy. If needed, add more pasta water to achieve desired consistency.\n",
      "6. Season with salt to taste.\n",
      "7. Serve hot and enjoy your homemade Cacio e Pepe!\n"
     ]
    }
   ],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)\n",
    "print(overall_chain.run(\"Rome\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efe9ffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arguments': '{\"location\":\"Boston\",\"unit\":\"celsius\"}', 'name': 'get_current_weather'}\n",
      "get_current_weather(**{\"location\":\"Boston\",\"unit\":\"celsius\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_current_weather(location, unit):\n",
    "    return 37.5\n",
    "\n",
    "functions=[{\n",
    "    \"name\": \"get_current_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "output = chat(messages=[\n",
    "    SystemMessage(content=\"You are an helpful AI bot\"),\n",
    "    HumanMessage(content=\"What’s the weather like in Boston right now?\")\n",
    "], functions=functions)\n",
    "\n",
    "f_call_str = output.additional_kwargs[\"function_call\"]\n",
    "print(f_call_str)\n",
    "\n",
    "f_call = \"{func_name}(**{func_kwargs})\".format(func_name=f_call_str[\"name\"], func_kwargs=f_call_str[\"arguments\"])\n",
    "print(f_call)\n",
    "eval(f_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f63a7a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arguments': '{\"location\":\"Boston\",\"unit\":\"celsius\"}', 'name': 'get_current_weather'}\n",
      "get_current_weather(**{\"location\":\"Boston\",\"unit\":\"celsius\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_current_weather(location, unit):\n",
    "    return 37.5\n",
    "\n",
    "output = chat(messages=\n",
    "     [\n",
    "         SystemMessage(content=\"You are an helpful AI bot\"),\n",
    "         HumanMessage(content=\"What’s the weather like in Boston right now?\")\n",
    "     ],\n",
    "     functions=[{\n",
    "         \"name\": \"get_current_weather\",\n",
    "         \"description\": \"Get the current weather in a given location\",\n",
    "         \"parameters\": {\n",
    "             \"type\": \"object\",\n",
    "             \"properties\": {\n",
    "                 \"location\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                 },\n",
    "                 \"unit\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                 }\n",
    "             },\n",
    "             \"required\": [\"location\"]\n",
    "         }\n",
    "     }\n",
    "     ]\n",
    ")\n",
    "\n",
    "f_call_str = output.additional_kwargs[\"function_call\"]\n",
    "print(f_call_str)\n",
    "\n",
    "f_call = \"{func_name}(**{func_kwargs})\".format(func_name=f_call_str[\"name\"], func_kwargs=f_call_str[\"arguments\"])\n",
    "print(f_call)\n",
    "eval(f_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b5ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aihack_py3.9",
   "language": "python",
   "name": "aihack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
